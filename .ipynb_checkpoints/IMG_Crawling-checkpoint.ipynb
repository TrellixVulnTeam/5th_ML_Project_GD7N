{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302762c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb2eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\jupyter_home\\Machine_Learning\\ML_Project_5th\\5th_ML_Project\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49ca43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d0cf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:/jupyter_home/Machine_Learning/ML_Project_5th/5th_ML_Project/chromedriver_win32/chromedriver.exe\") # 크롬드라이버 설치한 경로 작성 필요 \n",
    "driver.get(\"https://www.google.co.kr/imghp?hl=ko&tab=wi&authuser=0&ogbl\")\n",
    "driver.set_window_size(1920, 1080)\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "name = '눈 감은 사람'\n",
    "elem.send_keys(name)\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ee16180",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4120778651.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [26]\u001b[1;36m\u001b[0m\n\u001b[1;33m    path = \"C:\\jupyter_home\\Machine_Learning\\ML_Project_5th\\5th_ML_Project\\Data\\IMG_Crwaling\" #저장할 경로\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "imgs = driver.find_elements_by_css_selector(\".rg_i.Q4LuWd\") #작게 뜬 이미지들 모두 선택(elements)\n",
    "for img in imgs:\n",
    "    try:\n",
    "        img.click()\n",
    "        time.sleep(2)\n",
    "        imgUrl = driver.find_element_by_xpath(\n",
    "                '//*[@id=\"Sva75c\"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img').get_attribute(\n",
    "                \"src\") # 크게 뜬 이미지 선택하여 \"src\" 속성을 받아옴\n",
    "    path = \"C:\\jupyter_home\\Machine_Learning\\ML_Project_5th\\5th_ML_Project\\Data\\IMG_Crwaling\" #저장할 경로\n",
    "        urllib.request.urlretrieve(imgUrl, path + name + str(count) + \".jpg\") // \n",
    "        count = count + 1\n",
    "        if count > 260: #다운 받을 이미지 갯수 조정\n",
    "            break\n",
    "    except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da3866",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a10236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3caca5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\jupyter_home\\Machine_Learning\\ML_Project_5th\\5th_ML_Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff809117",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64370996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a99dbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\jupyter_home\\\\Machine_Learning\\\\ML_Project_5th\\\\5th_ML_Project'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67008bd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왜 안됨?\n"
     ]
    }
   ],
   "source": [
    "chromedriver = \"C:/jupyter_home/Machine_Learning/ML_Project_5th/5th_ML_Project/chromedriver_win32/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.set_window_size(1920, 1080)\n",
    "driver.get(\"https://search.naver.com/search.naver?where=image&sm=tab_jum&query=\")\n",
    "\n",
    "elem = driver.find_element_by_name(\"query\")\n",
    "elem.send_keys(\"눈 감은 사진\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "\n",
    "try:\n",
    "    driver.find_elements_by_css_selector(\"_image\")[0].click()\n",
    "except:\n",
    "    print(\"왜 안됨?\")\n",
    "\n",
    "#driver.find_elements_by_css_selector(\"_image_listImage\")[0].click()\n",
    "#driver.find_elements_by_css_selector(\".tile_item._item\")[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70260980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138a0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "chromedriver = \"C:/jupyter_home/Machine_Learning/ML_Project_5th/5th_ML_Project/chromedriver_win32/chromedriver.exe\"\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "driver = webdriver.Chrome(chromedriver, options=options)\n",
    "driver.set_window_size(1920, 1080)\n",
    "\n",
    "driver.get(\"https://search.naver.com/search.naver?where=image&sm=tab_jum&query=\")\n",
    "\n",
    "elem = driver.find_element_by_name(\"query\")\n",
    "elem.send_keys(\"눈 감은 사진\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    driver.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "    time.sleep(10)\n",
    "    time.sleep(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "def fetch_list_url():\n",
    "    params = []\n",
    "    imgList = soup.find_all(\"img\", class_=\"_img\")\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url()\n",
    "    for idx,p in enumerate(params,1):\n",
    "        urllib.request.urlretrieve(p, \"C:\\jupyter_home\\Machine_Learning\\ML_Project_5th\\5th_ML_Project\\Data\\IMG_Crwaling\" + str(idx) + \".jpg\")\n",
    "fetch_detail_url()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb83990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote_plus\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query='\n",
    "plusUrl = input('검색어를 입력하세요.')\n",
    "url = baseUrl + quote_plus(plusUrl)\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "img = soup.find_all(class_=\"_image _listImage\")\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420135b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요.눈 감은 사진\n",
      "끝\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "baseUrl = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query='\n",
    "plusUrl = input('검색어를 입력하세요.')\n",
    "url = baseUrl + quote_plus(plusUrl)\n",
    "html = urlopen(url)\n",
    "soup = bs(html, 'html.parser')\n",
    "img = soup.find_all(class_ = '_image')\n",
    "\n",
    "dir_path = './Data/IMG_Crwaling/'\n",
    "dir_name = plusUrl\n",
    "os.mkdir(dir_path + \"/\" + dir_name + \"/\")\n",
    "path = dir_path + \"/\" + dir_name + \"/\"\n",
    "n = 1\n",
    "\n",
    "for i in img:\n",
    "    imgUrl = i['data-source']\n",
    "    with urlopen(imgUrl) as f:\n",
    "        with open(path + plusUrl + str(n) + '.jpg','wb') as h:\n",
    "            img = f.read()\n",
    "            h.write(img)\n",
    "    n += 1\n",
    "print(\"끝\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a8d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528b589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e666b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img Save Success\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "def naver_get(name,url):    #네이버 이미지 \n",
    "    driver = webdriver.Chrome('C:/jupyter_home/Machine_Learning/ML_Project_5th/5th_ML_Project/chromedriver_win32/chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    body = driver.find_element_by_tag_name(\"body\")\n",
    "    num_of_pagedowns = 30\n",
    "\n",
    "    while num_of_pagedowns:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.3)\n",
    "        num_of_pagedowns -=1\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    my_titles = soup.find_all('img',class_=\"_img\")\n",
    "    \n",
    "    my_list=[]\n",
    "    for i in range(len(my_titles)):\n",
    "        my_list.append(my_titles[i]['src'])\n",
    "    count= 0\n",
    "    for i in my_list:\n",
    "        #딕셔너리를 순서대로 넣어줌\n",
    "        t = urllib.request.urlopen(i).read()\n",
    "        filename = \"./img/\"+name+\"/\"+str(count)+'.jpg'\n",
    "        with open(filename,\"wb\") as f:\n",
    "            f.write(t)\n",
    "        count+=1\n",
    "    print(\"Img Save Success\")\n",
    "    \n",
    "    \n",
    "naver_get('사막여우','https://search.naver.com/search.naver?where=image&sm=tab_jum&query=%EC%82%AC%EB%A7%89%EC%97%AC%EC%9A%B0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94e4e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 이미지 저장중\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib\n",
    "import os\n",
    "import requests\n",
    "\n",
    "chromedriver = \"C:/jupyter_home/Machine_Learning/ML_Project_5th/5th_ML_Project/chromedriver_win32/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.set_window_size(1920, 1080)\n",
    "driver.get(\"https://search.naver.com/search.naver?where=image&sm=tab_jum&query=\")\n",
    "\n",
    "elem = driver.find_element_by_name(\"query\")\n",
    "elem.send_keys(\"눈 감은 사진\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "img_src = driver.find_elements_by_css_selector(\"_image_listImage\")\n",
    "\n",
    "img_list = [ ] #이미지 링크 저장할 리스트\n",
    "\n",
    "for j in img_src :\n",
    "    img_src1 = j['src']\n",
    "    img_list.append(img_src1)\n",
    "    count += 1\n",
    "\n",
    "file_no = 0\n",
    "for j in range(0,len(img_list)) :\n",
    "    try :\n",
    "        urllib.request.urlretrieve(img_list[j],str(file_no)+'.jpg') #현재폴더에 이미지 저장하기\n",
    "    except :\n",
    "        continue\n",
    "\n",
    "file_no += 1\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b63e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
